{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\n",
      "Data format: \n",
      "--------------------------------\n",
      "type(train_datas[i].data[0]) -> <class 'torch.Tensor'>\n",
      "train_datas[i].data[0].dtype -> torch.float32\n",
      "\n",
      "type(train_datas[i].targets) -> <class 'torch.Tensor'>\n",
      "train_datas[i].targets.dtype -> torch.int64\n",
      "\n",
      "\n",
      "Access Data by indexing\n",
      "--------------------------------\n",
      "train_datas[i][0] -> (torch.Size([3, 32, 32]), torch.Size([]))\n",
      "\n",
      "\n",
      "max and min values of train_datas[i].data:\n",
      "--------------------------------\n",
      "\t[(tensor(0.), tensor(1.))]\n",
      "\n",
      "\n",
      "================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Cifar10HelperFunctions.GetStandardData import class_wise_preprocessed_cifar10\n",
    "train_datas, test_datas, test_data_for_repository = class_wise_preprocessed_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "repository_size = 10\n",
    "# NUM_DIMENSIONS = 28*28\n",
    "NUM_EPOCHS = 100\n",
    "label_for_zero = 0\n",
    "BATCH_SIZE = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "n_train_zeros = 300_000\n",
    "n_test_zeros = 100_000\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-0 training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harikrishnam/.local/lib/python3.11/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...(epochs: 100)\n",
      "Epoch: 0\n",
      "----------------\n",
      "Epoch: 1\n",
      "----------------\n",
      "Epoch: 2\n",
      "----------------\n",
      "Epoch: 3\n",
      "----------------\n",
      "Epoch: 4\n",
      "----------------\n",
      "Epoch: 5\n",
      "----------------\n",
      "Epoch: 6\n",
      "----------------\n",
      "Epoch: 7\n",
      "----------------\n",
      "Epoch: 8\n",
      "----------------\n",
      "Epoch: 9\n",
      "----------------\n",
      "Epoch: 10\n",
      "----------------\n",
      "Epoch: 11\n",
      "----------------\n",
      "Epoch: 12\n",
      "----------------\n",
      "Epoch: 13\n",
      "----------------\n",
      "Epoch: 14\n",
      "----------------\n",
      "Epoch: 15\n",
      "----------------\n",
      "Epoch: 16\n",
      "----------------\n",
      "Epoch: 17\n",
      "----------------\n",
      "Epoch: 18\n",
      "----------------\n",
      "Epoch: 19\n",
      "----------------\n",
      "Epoch: 20\n",
      "----------------\n",
      "Epoch: 21\n",
      "----------------\n",
      "Epoch: 22\n",
      "----------------\n",
      "Epoch: 23\n",
      "----------------\n",
      "Epoch: 24\n",
      "----------------\n",
      "Epoch: 25\n",
      "----------------\n",
      "Epoch: 26\n",
      "----------------\n",
      "Epoch: 27\n",
      "----------------\n",
      "Epoch: 28\n",
      "----------------\n",
      "Epoch: 29\n",
      "----------------\n",
      "Epoch: 30\n",
      "----------------\n",
      "Epoch: 31\n",
      "----------------\n",
      "Epoch: 32\n",
      "----------------\n",
      "Epoch: 33\n",
      "----------------\n",
      "Epoch: 34\n",
      "----------------\n",
      "Epoch: 35\n",
      "----------------\n",
      "Epoch: 36\n",
      "----------------\n",
      "Epoch: 37\n",
      "----------------\n",
      "Epoch: 38\n",
      "----------------\n",
      "Epoch: 39\n",
      "----------------\n",
      "Epoch: 40\n",
      "----------------\n",
      "Epoch: 41\n",
      "----------------\n",
      "Epoch: 42\n",
      "----------------\n",
      "Epoch: 43\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "from ZeroHelperFunctions.DataLoadersForZero import DataLoadersForZero\n",
    "from Networks.networks import ClassWiseVGGNet\n",
    "from ZeroHelperFunctions.zeroTrainer import ZeroTrainer\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from ZeroHelperFunctions import plots\n",
    "from ZeroHelperFunctions.Curiosity import CuriosityRover\n",
    "\n",
    "mnist_rover = CuriosityRover(device=device)\n",
    "\n",
    "for cl in range(repository_size):\n",
    "    print(f\"Class-{cl} training ...\")\n",
    "    dl = DataLoadersForZero(train_data=train_datas[cl],\n",
    "                            test_data=test_datas[cl],\n",
    "                            image_shape=(3, 32, 32))\n",
    "    dl.make_dataloaders(batch_size=BATCH_SIZE,\n",
    "                        n_train_zeros=n_train_zeros,\n",
    "                        n_test_zeros=n_test_zeros,\n",
    "                        label_for_zero=label_for_zero)\n",
    "    # dl.show_border_images_of_combined_data(6000)\n",
    "    dl.generate_zero_class_dataloader(10000, BATCH_SIZE)\n",
    "    zero_model = ClassWiseVGGNet(out_nodes=2)\n",
    "    zero_trainer = ZeroTrainer(model=zero_model,\n",
    "                               number_of_non_zero_classes=1,\n",
    "                               train_dl=dl.train0_dataloader,\n",
    "                               test_dl=dl.test_dataloader,\n",
    "                               purity_fact_dl=dl.test0_dataloader,\n",
    "                               zero_dl=dl.zero_dataloader,\n",
    "                               loss_fn=nn.CrossEntropyLoss(),\n",
    "                               optimizer=torch.optim.SGD(params=zero_model.parameters(), lr=learning_rate),\n",
    "                               label_of_zero_class=label_for_zero,\n",
    "                               device=device)\n",
    "    zero_trainer.train(epochs=NUM_EPOCHS)\n",
    "    plots.plot_pf(zero_trainer.purities, title=f\"class-{cl}\", path=\"plots/cifar_singles/purity\")\n",
    "    plots.plot_of(zero_trainer.occupancy, title=f\"class-{cl}\", path=\"plots/cifar_singles/occupancy\")\n",
    "    plots.plot_train_test_losses(zero_trainer.train_loss,\n",
    "                                 zero_trainer.test_loss, title=f\"class-{cl}\", path=\"plots/cifar_singles/losses\")\n",
    "    plots.plot_train_test_accs(zero_trainer.train_acc,\n",
    "                               zero_trainer.test_acc, title=f\"class-{cl}\", path=\"plots/cifar_singles/accs\")\n",
    "    mnist_rover.add_model_for_an_anomaly(zero_model, f\"MNIST - {cl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader_for_repository = DataLoader(test_data_for_repository,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZeroHelperFunctions.Mismatches import Mismatches\n",
    "mismatch = Mismatches(test_dataloader_for_repository, mnist_rover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch.test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZeroHelperFunctions.zero_class_images_generator_mnist import ZeroClassDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector_data = ZeroClassDataset(num_samples=10, image_shape=(3, 32, 32), label=label_for_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector_data.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZeroHelperFunctions.show_image import show_one_color_image\n",
    "show_one_color_image(zero_vector_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xk = zero_vector_data.data[0]\n",
    "\n",
    "def generate(starting_noise, class_name, step_size, iterations=100, print_freq=10):\n",
    "    xk = starting_noise\n",
    "    xk = xk.clone().detach().requires_grad_(True) \n",
    "    xk.shape, xk.requires_grad\n",
    "    zero_model = mnist_rover.learned_anomaly_models[class_name]\n",
    "    zero_model.eval()\n",
    "    logits = zero_model(xk.to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    target_logit = logits[:, 1]\n",
    "    target_logit\n",
    "    target_logit.backward()\n",
    "    gradients = xk.grad\n",
    "    xk = xk + gradients * step_size\n",
    "    xk[0].shape\n",
    "    print(\"wtf\")\n",
    "    show_one_color_image(xk[0].detach().cpu().numpy())\n",
    "    for i in range(iterations):\n",
    "        xk = xk.clone().detach().requires_grad_(True) \n",
    "        xk.shape, xk.requires_grad\n",
    "        zero_model.eval()\n",
    "        logits = zero_model(xk.to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        target_logit = logits[:, 1]\n",
    "        target_logit\n",
    "        target_logit.backward()\n",
    "        gradients = xk.grad\n",
    "        xk = xk + gradients * step_size\n",
    "        xk[0].shape\n",
    "        if i % print_freq == 0:\n",
    "            print(\"iteration number: \", i)\n",
    "            show_one_color_image(xk[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(starting_noise=zero_vector_data.data[0].unsqueeze(0), \n",
    "         class_name=0, \n",
    "         step_size=0.01, \n",
    "         iterations=3001,\n",
    "         print_freq=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
